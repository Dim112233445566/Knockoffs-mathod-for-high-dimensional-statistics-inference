# Knockoffs变量选择方法分析报告

## 项目概述

这是一个高维统计推断课程期末报告项目，对比分析了**Lasso回归**和**Knockoffs方法**两种变量选择方法的性能。

---

## 1. 改进内容

### 1.1 代码结构问题修复

| 问题 | 原因 | 修复方案 |
|------|------|---------|
| 变量覆盖 | 第24行重新定义 `n, p = size(X)` | 改为 `n_samples, n_vars = size(X)` |
| FDR计算混淆 | 混淆了Lasso的FDR和目标FDR | 清晰分离两个概念 |
| 缺少详细统计 | 只有基础结果输出 | 添加TP/FP/FN等详细统计指标 |

### 1.2 增强功能

1. **详细的参数输出**：显示数据生成的参数
2. **规范的结果统计**：
   - 真阳性(TP)：正确识别的因果变量
   - 假阳性(FP)：错误识别的无关变量
   - 假阴性(FN)：遗漏的因果变量
3. **对比分析**：Lasso vs Knockoffs的详细对比
4. **可视化成果**：生成4个对比图表
5. **结论总结**：自动判断两种方法的优劣

---

## 2. 数据生成设置

| 参数 | 值 | 说明 |
|------|-----|------|
| 样本数 (n) | 500 | 有限样本，高维问题（p >> n） |
| 变量数 (p) | 1000 | 典型的高维设置 |
| 相关系数 (ρ) | 0.4 | 中等程度的变量相关性 |
| 真实非零系数 (k) | 50 | 约5%的稀疏性 |
| 协方差矩阵 | Toeplitz结构 | 反映实际数据的相关性 |

---

## 3. 方法说明

### 3.1 Lasso回归方法

**原理**：通过L1正则化实现变量选择

$$\hat{\beta}^{Lasso} = \arg\min_{\beta} \|y - X\beta\|_2^2 + \lambda\|\beta\|_1$$

**流程**：
1. 使用10折交叉验证选择最优正则化参数 λ
2. 用最优λ对全数据进行拟合
3. 评估统计幂和虚发现率

**优点**：计算快速，直观易懂
**缺点**：没有FDR控制保证，虚发现率可能较高

### 3.2 Knockoffs方法

**原理**：创建"假克隆"变量，与原变量相关但与响应变量无关

$$W_j = \text{sign}(\text{Knockoff统计量}_j) \times |\text{Knockoff统计量}_j|$$

**特点**：
- 不依赖数据分布假设
- 提供对FDR的理论保证
- 可在多个FDR目标水平下评估

**优势**：FDR严格控制，统计幂往往更高

---

## 4. 预期结果分析

### 4.1 主要对比指标

#### 统计幂 (Power)
- **定义**：$\text{Power} = \frac{TP}{k}$（正确识别的因果变量比例）
- **期望**：Knockoffs通常具有更高的幂

#### 虚发现率 (FDR)
- **定义**：$\text{FDR} = \frac{FP}{\max(|S|, 1)}$（所有选中变量中虚阳性的比例）
- **期望**：
  - Lasso可能超过预期水平
  - Knockoffs严格控制在目标水平以下

### 4.2 权衡分析

在FDR目标设为0.10时：
- **Lasso**：可能具有较低的虚发现率，但幂也较低
- **Knockoffs**：保证FDR≤0.10，同时获得更高的幂

---

## 5. 代码改进亮点

### 5.1 结构化设计
```julia
# 清晰的三部分流程
# Part 1: Lasso变量选择
# Part 2: Knockoffs变量选择
# Part 3: 可视化和对比分析
```

### 5.2 完整的统计输出
```
✓ 选中变量个数
✓ 真阳性/假阳性/假阴性计数
✓ 统计幂和虚发现率
✓ 对比分析和改进度
```

### 5.3 多维度可视化
1. **左上**：Knockoffs的幂-FDR曲线
2. **右上**：Knockoffs的FDR控制情况
3. **左下**：两种方法的幂对比（条形图）
4. **右下**：两种方法的FDR对比（条形图）

---

## 6. 使用说明

### 6.1 环境需求
```julia
using Knockoffs      # 主要的Knockoffs包
using Random         # 随机数生成
using GLMNet         # Lasso回归
using Distributions  # 统计分布
using LinearAlgebra  # 线性代数
using ToeplitzMatrices # 特殊矩阵类型
using StatsKit       # 统计工具
using Plots          # 绘图
using Printf         # 格式化输出
```

### 6.2 运行步骤
1. 确保安装了所有必需的Julia包
2. 在Julia REPL中运行：`include("Knockoffs.jl")`
3. 程序将自动生成：
   - 控制台输出：详细的统计结果
   - 图表文件：`knockoffs_vs_lasso.png`

### 6.3 参数调整

如需修改实验设置，可调整以下参数：
- `n = 500`：样本数
- `p = 1000`：变量数
- `k = 50`：真实非零系数个数
- `rho = 0.4`：协方差结构的相关系数
- `nsims = 10`：Knockoffs模拟次数

---

## 7. 理论背景

### 7.1 为什么Knockoffs更优？

**FDR控制的理论保证**：
- Knockoffs提供了对虚发现率的有限样本控制
- 基于交换对称性(Exchangeability)原理
- 在无分布假设下工作

**统计幂的提升机制**：
- 通过对比原变量和假克隆变量的统计量
- 利用了变量间的相关结构
- 更好地利用了高维信息

### 7.2 Knockoffs的两大变体

1. **Model-X Knockoffs (MVR)**：本项目使用
   - 假设协变量的联合分布已知
   - 不依赖模型假设

2. **Model-Free Knockoffs**：
   - 直接从原始数据推导
   - 更灵活但计算更复杂

---

## 8. 预期发现

基于高维统计理论，预期在此设置下观察到：

| 指标 | Lasso | Knockoffs | 说明 |
|------|-------|----------|------|
| 统计幂 | 0.40-0.60 | 0.70-0.85 | Knockoffs通常更高 |
| FDR | 0.05-0.20 | ≤目标值 | Knockoffs严格控制 |
| 变量选择 | 波动较大 | 相对稳定 | 通过多次模拟评估 |

---

## 9. 报告输出

最终生成的可视化将包含：
- 左上图：Knockoffs方法在不同FDR目标下的幂-FDR权衡
- 右上图：Knockoffs的FDR控制情况（与理想y=x线对比）
- 左下图：两种方法的统计幂直接对比
- 右下图：两种方法的虚发现率直接对比

---

## 10. 学习目标达成

通过这个项目，学生可以：
✓ 理解Knockoffs的核心原理和优势
✓ 掌握变量选择方法的评估指标
✓ 学习FDR控制的重要性
✓ 实践高维统计方法的编程实现
✓ 学会通过可视化展示统计结果

---

**项目完成日期**：2025年10月
**编程语言**：Julia
**核心包版本**：Knockoffs.jl, GLMNet.jl, Plots.jl
